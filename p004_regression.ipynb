{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p004_regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqfHft3bYTJwVQeLKpi4Oi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansglick/book_errata/blob/main/p004_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RAaNsw-IVJ4A"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Le layer normalisation prend des batch de features continues et va les normer, i.e. moyenne de zéro, std de 1\n",
        "# Le layer normalisation fonctionne de la manière suivante\n",
        "# 1/ Il doit d'abord être instancié\n",
        "# 2/ Avoir à disposition des data adapt, à savoir sur qui vont être compute la mean et la variance\n",
        "# 3/ Adapter le layer afin d'évaluer les stats basics\n",
        "layer = tf.keras.layers.Normalization(axis=-1) #1\n",
        "adapt_data = np.array([[0., 7., 4.],\n",
        "                       [2., 9., 6.],\n",
        "                       [0., 7., 4.],\n",
        "                       [2., 9., 6.]], dtype='float32') #2\n",
        "layer.adapt(adapt_data) #3"
      ],
      "metadata": {
        "id": "NKlCoKD4Xtk9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Application du layer à un numpy array\n",
        "input_data = np.array([[0., 7., 4.]], dtype='float32')\n",
        "layer(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG_THJh_X0fD",
        "outputId": "4d229416-0b4d-4d13-85e0-57be9db576bb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-1., -1., -1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On peut télécharger un dataframe via la fonction read_csv() de pandas\n",
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(url, names=column_names,\n",
        "                          na_values='?', comment='\\t',\n",
        "                          sep=' ', skipinitialspace=True)"
      ],
      "metadata": {
        "id": "05qykuqLwtLR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove les NAs\n",
        "# Dummification de la variable Origin pour le réseau de neurones\n",
        "dataset = raw_dataset.copy()\n",
        "dataset = dataset.dropna()\n",
        "dataset[\"Origin\"] = dataset[\"Origin\"].map({1:\"USA\",2:\"Europe\",3:\"Japan\"})\n",
        "dataset = pd.get_dummies(dataset, columns = ['Origin'], prefix=\"\", prefix_sep=\"\")"
      ],
      "metadata": {
        "id": "dV_4sugkxxHQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création de labels et features et train,set\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "train_labels = train_features.pop('MPG')\n",
        "test_labels = test_features.pop('MPG')"
      ],
      "metadata": {
        "id": "d59RzYwhx1Oo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création du modèle\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(train_features))\n",
        "linear_model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])"
      ],
      "metadata": {
        "id": "ywVXjONP75P1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test & prédiction\n",
        "linear_model.predict(train_features[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MQkm7ED8hY1",
        "outputId": "a4ed2e94-f70f-42cc-b732-9b239d290a77"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.7508768 ],\n",
              "       [-0.86499375],\n",
              "       [-1.4448656 ],\n",
              "       [ 0.6345582 ],\n",
              "       [ 1.1647086 ],\n",
              "       [-1.2364887 ],\n",
              "       [ 1.1328601 ],\n",
              "       [-1.308997  ],\n",
              "       [-0.7821326 ],\n",
              "       [ 0.7988956 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilation du modèle\n",
        "linear_model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "CIJKjdKd9B32"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training du modèle\n",
        "history = linear_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    verbose=0,\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "DHPzktVOARyc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction qui définit une architecture et renvoie le modele compilé\n",
        "def build_and_compile_model(norm):\n",
        "  model = tf.keras.Sequential([\n",
        "      norm,\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model"
      ],
      "metadata": {
        "id": "51aDy82oA9eb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrianement du modele\n",
        "nn_model = build_and_compile_model(normalizer)\n",
        "nn_model.fit(train_features,train_labels,validation_split=0.2,verbose=0,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSwb6I7NBnKo",
        "outputId": "dd9df205-2f49-4cbf-ab28-306227e8222d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8675e07510>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation du modele réseau de neurones\n",
        "nn_model.evaluate(test_features, test_labels, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDc1Jd2QC8hx",
        "outputId": "a7e836da-f209-40ef-e3e6-9e4948c2b905"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7175453901290894"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation du modele réseau de neurones\n",
        "linear_model.evaluate(test_features, test_labels, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idbo5h6aDo_t",
        "outputId": "f1d7588f-3fbd-4142-b858-b09458dc9e34"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4735820293426514"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}