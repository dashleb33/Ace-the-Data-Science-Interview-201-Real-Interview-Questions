{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p018_padding_and_masking.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMz+W0HGUuBh9QRs8dThYnU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansglick/book_errata/blob/main/p018_padding_and_masking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaVcCgUTSZaE",
        "outputId": "4c8533ac-a693-466a-da87-61620d6e985f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objectif\n",
        "Manipuler les outils de tensorflow relatif au padding et au masking"
      ],
      "metadata": {
        "id": "MFaairllSfNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = [\n",
        "    [711, 632, 71],\n",
        "    [73, 8, 3215, 55, 927],\n",
        "    [83, 91, 1, 645, 1253, 927],\n",
        "]"
      ],
      "metadata": {
        "id": "APlCoR4USzD2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding Simple\n",
        "Le moyen le plus simple est d'utiliser un layer padding `tf.keras.preprocessing.sequence.pad_sequences()` sur un tensor classique ou une liste\n"
      ],
      "metadata": {
        "id": "yn5GTyNpTDGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    raw_inputs, padding=\"post\"\n",
        ")\n",
        "print(padded_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzt7AsCnS9kK",
        "outputId": "468a4c93-ac0b-4a89-a5dd-92b0cd45d9f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 711  632   71    0    0    0]\n",
            " [  73    8 3215   55  927    0]\n",
            " [  83   91    1  645 1253  927]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding et Masking\n",
        "\n",
        "Une fois que nos séquences sont padded, il faut être en mesure d'informer le modèle que certains tokens (ceux issus du padding) ne doivent pas être pris en compte lors du calcul de la loss. Autrement dit, il faut être capable de propager le masking de ces tokens. 3 Manières de le faire : \n",
        " * Via un layer Masking `keras.layers.Masking`\n",
        "   * Sous le capot, ce type de layer a un attribut `._keras_mask` qui représente le mask. `False` indique une valeur rembourée\n",
        " * Via un layer Embedding `keras.layers.Embedding` avec l'argument `mask_zero=True`\n",
        "    * Sous le capot, ce type de layer a un attribut `._keras_mask` qui représente le mask. `False` indique une valeur rembourée\n",
        " * Manuellement lors du call des layers"
      ],
      "metadata": {
        "id": "OQh21VOKTRBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
        "masked_output = embedding(padded_inputs)\n",
        "print(padded_inputs)\n",
        "print(\"\")\n",
        "print(masked_output.shape)\n",
        "print(masked_output[-1])\n",
        "print(\"\")\n",
        "print(masked_output._keras_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0UmWXMcUz8-",
        "outputId": "a1edea2d-bdf3-4b91-c875-85f553820189"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 711  632   71    0    0    0]\n",
            " [  73    8 3215   55  927    0]\n",
            " [  83   91    1  645 1253  927]]\n",
            "\n",
            "(3, 6, 16)\n",
            "tf.Tensor(\n",
            "[[-0.00746113 -0.01262882  0.04603639  0.0171973  -0.01106896 -0.01516137\n",
            "  -0.03219961  0.04006619  0.02056657 -0.00426289 -0.0479543  -0.02133725\n",
            "  -0.04114251  0.02001885 -0.03566091 -0.03189234]\n",
            " [-0.03131612 -0.01921284 -0.04121875  0.03731486  0.0118412   0.02039745\n",
            "  -0.00700837  0.04200404 -0.01960441  0.01622865 -0.04365989 -0.04678912\n",
            "   0.0417749   0.04169219 -0.0342247   0.02585191]\n",
            " [ 0.02819878  0.03639678  0.01235443  0.02570499  0.04898168 -0.04376384\n",
            "   0.04949386  0.02300647 -0.01527071 -0.01705949 -0.0031818  -0.03190134\n",
            "   0.01958735  0.04385548 -0.0096609  -0.02756597]\n",
            " [-0.04424386 -0.02971691  0.04504538 -0.004831   -0.01226246 -0.01563602\n",
            "  -0.0036243   0.04886606  0.02557868  0.03063506 -0.02767084 -0.03097909\n",
            "   0.03716192 -0.0439463   0.02472824  0.01783756]\n",
            " [-0.02402784 -0.00328664 -0.02484034  0.00734135  0.00333361  0.01876425\n",
            "   0.01017188 -0.04145621  0.03873109 -0.02816863 -0.03887383  0.03338636\n",
            "  -0.00363987 -0.04903182 -0.02783325 -0.04400401]\n",
            " [-0.03352523  0.03469061  0.02188517 -0.0481311   0.03465548  0.03783778\n",
            "   0.02097162  0.00682812 -0.00902719 -0.03824946  0.02029203  0.00516053\n",
            "   0.00183892  0.01271899 -0.00988423 -0.02107246]], shape=(6, 16), dtype=float32)\n",
            "\n",
            "tf.Tensor(\n",
            "[[ True  True  True False False False]\n",
            " [ True  True  True  True  True False]\n",
            " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Propagation du mask\n",
        "Pour un des deux types de layers ci-dessus, le mask est propagé dans le réseau, tant que le layer suivant est capable de l'appliquer, j'imagine que ça signifie tant qu'il a une shape compatible. Ce processus fonctionne aussi bien sur l'API fonctionnelle que séquentielle. \n",
        "\n",
        " * La couche embedding peut produire un mask. Elle possède une méthode `.compute_mask()` qui crée un mask\n",
        " * La couche LSTM peut alors utiliser le mask crée par l'embedding\n",
        " * self.embedding = `layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)`\n",
        " * `self.lstm = layers.LSTM(32)`\n",
        " * `mask = self.embedding.compute_mask(inputs)`\n",
        " * `output = self.lstm(x, mask=mask)`"
      ],
      "metadata": {
        "id": "cwqYOdeBVWvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple d'un compute_mask method\n",
        "def compute_mask(self, inputs, mask=None):\n",
        "    if not self.mask_zero:\n",
        "        return None\n",
        "    return tf.not_equal(inputs, 0)"
      ],
      "metadata": {
        "id": "rPMPwZkabSO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalSoftmax(tf.keras.layers.Layer):\n",
        "    def call(self, inputs, mask=None):\n",
        "        broadcast_float_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n",
        "        inputs_exp = tf.exp(inputs) * broadcast_float_mask\n",
        "        inputs_sum = tf.reduce_sum(\n",
        "            inputs_exp * broadcast_float_mask, axis=-1, keepdims=True\n",
        "        )\n",
        "        return inputs_exp / inputs_sum\n",
        "\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(None,), dtype=\"int32\")\n",
        "x = tf.keras.layers.Embedding(input_dim=10, output_dim=32, mask_zero=True)(inputs)\n",
        "x = tf.keras.layers.Dense(1)(x)\n",
        "outputs = TemporalSoftmax()(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "vREm2XdefWeJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indata = np.random.randint(0, 10, size=(32, 100))\n",
        "outdata = np.random.random((32, 100, 1))\n",
        "res = model(indata,outdata)"
      ],
      "metadata": {
        "id": "AgksZOHhfXKi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[22]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt6sKCpJf3b4",
        "outputId": "58614a0f-68ca-4193-e676-3078c644d32b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 1), dtype=float32, numpy=\n",
              "array([[ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [nan],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.],\n",
              "       [ 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}