{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "008_VAE_custom_all.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIVdI4Ph4nQ7GaSclGoN9i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansglick/book_errata/blob/main/008_VAE_custom_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RXIbMe-efZV",
        "outputId": "0827258e-74d7-4ba2-ddd6-b20262f20fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objectif\n",
        "\n",
        "L'objectif du notebook est de construire un VAE from scratch sur les données keras MNIST disponibles ic : tf.keras.datasets.mnist.load_data(). Cela se fera en plusieurs étapes :\n",
        "\n",
        "# Pense bete Concernant le subclassing\n",
        " * def __init__(self,.., **kwargs):\n",
        " * super(nom de la nouvelle classe, self).__init__(name=name, **kwargs)\n",
        " * def call(self, inputs):\n",
        " * super suit juste aprèsle init\n",
        " \n",
        "\n",
        "\n",
        "### Step 1 - Custom Sampling Layer\n",
        "Ici on veut subclasser layer pour créer un le sampling layer du VAE :     \n",
        " * 2 inputs : z_mean et z_log_var qui sont deux concaténés dans le dernier layer de l'encoder\n",
        " * Création du vecteur epsilon qui est de la mm taille que z_mean et qui contient des données issues du loi normale centrée réduite\n",
        " * Transformation de z_log_var en exponentiel(0.5*z_log_var)\n",
        " * Renvoyer la somme de t(z_log_var) et epsilon\n",
        " * Extrêmement simple car les calculs de dépendent que de l'input du layer\n",
        "\n",
        "### Step 2 - Custom Encoder Layer\n",
        "Ici on subclass layer pour obtenir la première partie du VAE, i.e. l'encoder. Celui-ci doit renvoyer un tuple (z_mean, z_log_var, et z qui est la solution finale). La raison pour laquelle on garde z_mean et z_log_var c'est parce qu'on en aura besoin plus tard lors du calcul de la loss dans le model\n",
        " * latent dim\n",
        " * intermediate dim\n",
        "\n",
        "### Step 3 - Custom Decoder Layer\n",
        "Ici on sublcass layer pour obtenir la derniere partie du VAE, le decoder. Celui-ci prend comme input le z de l'encoder et va le décompresser jusqu'à lla shape de l'image original\n",
        " * original dim\n",
        " * intermediate dim\n",
        "\n",
        "### Step 4 - Custom Model\n",
        "Ici on subclass Model de sorte à créer un nouveay modèle préprogrammé de tensorflow, un VAE, les inputs de celui-ci :     \n",
        " * original dimension\n",
        " * intermediate dimension\n",
        " * latent dimension\n",
        "\n",
        "### Step 5 - Récupération et Préprocessing des données\n",
        "Ici on veut récupérer les données, en faire un dataset object. On veut également préprocesser les données qui sont sous format rgb :    \n",
        " * / 255\n",
        " * Flatten l'image\n",
        " * Les foutre en float\n",
        "\n",
        "\n",
        "### Step 6 - Custom loop de training\n",
        "Ce qu'on veut :    \n",
        " * loss : mean square error + kl divergence\n",
        " * accumulateur loss : moyenne\n",
        " * on fait aussi le tape gradient\n",
        "\n",
        "\n",
        "# Schéma d'un VAE\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "8jJ8qfpkf4d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n_PeZxFuqcV9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour simuler une normale\n",
        "# tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "\n",
        "# Pour prendre une exponentielle, utiliser les fonctions tensorflow tf.exp\n",
        "# tf.exp(0.5 * z_log_var)\n",
        "\n",
        "# Pour sublclasser\n",
        "# class Sampling(layers.Layer)\n",
        "# class VariationalAutoEncoder(keras.Model)\n",
        "\n",
        "# Un layer peut prendre comme input call un tuple de layer !!!\n",
        "\n",
        "# C'est dans le subclassing de model dans le call qu'on calcule la loss\n",
        "# via self.add_loss(the_loss_to_add)\n",
        "\n",
        "# La KL divergence est égale à la moyenne du vecteur résultant d'opérations sur \n",
        "# z_mean et z_log_var\n",
        "# KL = -0.5 * Moyenne [ z_log_var - racine_carre(z_mean) - exp(z_log_var) + 1]\n",
        "\n",
        "# Warning : tf.reshape transforme un numpy array en eager tensor\n",
        "# Du coup utilisez .reshape de numpy si on veut conserver un numpy\n",
        "\n",
        "# take method de tensorflow dataset prend x élément au hasard et les fout dans un générator\n",
        "# Pour accéder à la valeur d'un générateur qui sort un tensor utilisez la méthode .numpy()\n",
        "\n",
        "# Pour les fonctions loss ne pas confondre\n",
        "# tf.keras.losses.MeanSquaredError() qui renvoie l'instanciation d'un objet qui peut s'appliquer alors comme une fonction \n",
        "# avec\n",
        "# tf.keras.losses.mean_squared_error qui est une fonction et non l'instanciation d'un objet\n",
        "\n",
        "# Pour mettre à jour les gradient on attend un iterateur de tuples (pente,variable)\n",
        "# optimizer.apply_gradients(zip(grads,model.trainable_weights))\n"
      ],
      "metadata": {
        "id": "HLNhM6G9s2nk"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling_Layer (tf.keras.layers.Layer):\n",
        "\n",
        "  \"\"\"\n",
        "  Le layer sampling dans un VAE\n",
        "  \"\"\"\n",
        "\n",
        "  def call(self,inputs):\n",
        "    z_mean,z_log_var = inputs\n",
        "\n",
        "    # Récupération de la shape de z_mean\n",
        "    batch = z_mean.shape[0]\n",
        "    dim = z_mean.shape[-1]\n",
        "\n",
        "    # Simulation de random normale\n",
        "    epsilon = tf.keras.backend.random_normal(shape = (batch,dim))\n",
        "\n",
        "    # Transformation de z_log_var\n",
        "    tz_log_var = tf.exp(0.5 * z_log_var)\n",
        "\n",
        "    # Retourne le sampling\n",
        "    sampling = epsilon + tz_log_var\n",
        "\n",
        "    return sampling"
      ],
      "metadata": {
        "id": "-sgL2htj_1mL"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "\n",
        "  \"\"\"\n",
        "  Le layer Encoder du VAE\n",
        "  \n",
        "  INPUTS : \n",
        "  - Intermediate dimension\n",
        "  - Latent dimension\n",
        "\n",
        "  OUTPUTS : \n",
        "  - triplet : z_mean,z_log_var,sampling\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,latent_dimension,intermediate_dimension,name = \"Encoder\",**kwargs):\n",
        "    super(Encoder, self).__init__(name=name, **kwargs)\n",
        "    self.denseA = tf.keras.layers.Dense(units = intermediate_dimension, activation = \"relu\")\n",
        "    self.denseB = tf.keras.layers.Dense(units = latent_dimension)\n",
        "    self.denseC = tf.keras.layers.Dense(units = latent_dimension)\n",
        "    self.sampling = Sampling_Layer()\n",
        "\n",
        "  def call(self,inputs):\n",
        "    proj = self.denseA(inputs)\n",
        "    z_mean = self.denseB(proj)\n",
        "    z_log_var =self.denseC(proj)\n",
        "    sampling = self.sampling((z_mean,z_log_var))\n",
        "    return z_mean,z_log_var,sampling\n",
        "    \n"
      ],
      "metadata": {
        "id": "PP8hsNzLBfzI"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "\n",
        "  \"\"\"\n",
        "  Le Decoder Layer d'un VAE\n",
        "  inputs :\n",
        "  - Original dimension\n",
        "  - Intermediate dimension \n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,intermediate_dimension,original_dimension,name = \"Decoder\",**kwargs):\n",
        "    super(Decoder,self).__init__(name=name, **kwargs)\n",
        "    self.denseA = tf.keras.layers.Dense(units = intermediate_dimension, activation =  \"relu\")\n",
        "    self.denseB = tf.keras.layers.Dense(units = original_dimension, activation = \"sigmoid\")\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = self.denseA(inputs)\n",
        "    x = self.denseB(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "EM6anhn1CpmW"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom_VAE(tf.keras.models.Model):\n",
        "  \"\"\"\n",
        "  Création d'une classe DE VAE à partir du sublcassing de Model\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,original_dimension,intermediate_dimension,latent_dimension,name = \"Custom_VAE\",**kwargs):\n",
        "    super(Custom_VAE,self).__init__(name = name,**kwargs)\n",
        "    self.encoder_layer = Encoder(latent_dimension,intermediate_dimension)\n",
        "    self.decoder_layer = Decoder(intermediate_dimension,original_dimension)\n",
        "\n",
        "  def call(self,inputs):\n",
        "    z_mean,z_log_var,sampling = self.encoder_layer(inputs)\n",
        "    x = self.decoder_layer(sampling)\n",
        "\n",
        "    # Calcul de la KL Loss\n",
        "    # KL = -0.5 * Moyenne [ z_log_var - racine_carre(z_mean) - exp(z_log_var) + 1]\n",
        "    kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
        "\n",
        "    # Ajout de la loss\n",
        "    self.add_loss(kl_loss)\n",
        "\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "HLdklQhFCqVC"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "original_dimension = 784\n",
        "intermediate_dimension = 64\n",
        "latent_dimension = 32\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "AIlNwAMNPX6q"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Récupération et Processing des données\n",
        "(x_train,y_train),_ = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0],original_dimension).astype(\"float32\")/255\n",
        "\n",
        "# Création d'un dataset object\n",
        "training_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "training_dataset = training_dataset.shuffle(buffer_size=1024).batch(64)"
      ],
      "metadata": {
        "id": "samaIYzWPfss"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Définitions des composants nécessaire à la custom loop\n",
        "model = Custom_VAE(original_dimension,intermediate_dimension,latent_dimension)\n",
        "loss_mse = tf.keras.losses.MeanSquaredError()\n",
        "loss_metric = tf.keras.metrics.Mean() # accumulator\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)"
      ],
      "metadata": {
        "id": "HPgLXi3DYKsV"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom loop\n",
        "\n",
        "for _ in range(epochs):\n",
        "\n",
        "  for step,batch in enumerate(training_dataset):\n",
        "    with tf.GradientTape() as tape :\n",
        "      predictions = model(batch)\n",
        "      loss = loss_mse(batch,predictions) + tf.reduce_sum(model.losses)\n",
        "    \n",
        "    # Récupération des pentes , i.e. les gradients\n",
        "    grads = tape.gradient(loss,model.trainable_weights)\n",
        "\n",
        "    # Mise à jour des gradients\n",
        "    optimizer.apply_gradients(zip(grads,model.trainable_weights))\n",
        "\n",
        "    # Accumulation sur tout les batch de la loss, moyenne sur tout les batch en cours\n",
        "    loss_metric(loss)\n",
        "\n",
        "    # Le display\n",
        "    if step % 1000 == 0:\n",
        "      print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7WvTdNVRzEX",
        "outputId": "1e69ca0c-5ded-422a-e3ff-2c0312c85128"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: mean loss = 0.3581\n",
            "step 0: mean loss = 0.0716\n",
            "step 0: mean loss = 0.0696\n",
            "step 0: mean loss = 0.0689\n",
            "step 0: mean loss = 0.0685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QNzfnwUpl9J1"
      },
      "execution_count": 128,
      "outputs": []
    }
  ]
}