{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hf_transformers_01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxiU4Q/a7TaTjxsfs2jilU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hansglick/book_errata/blob/main/hf_transformers_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-rNFESC9Lwk",
        "outputId": "7a90e7e5-d992-4dac-be73-4467f00e0fe7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organisation de la librairie\n",
        "\n",
        " La librairie `transformers` contient apparemment 5 modules :\n",
        "  * `transformers`\n",
        "  * `accelerate`\n",
        "  * `hub`\n",
        "  * `datasets`\n",
        "  * `tokenizers`\n",
        "\n",
        " \n",
        "## Parcours\n",
        "\n",
        " * chapitres 1->4 : utliser un modèle pretrained, le finetunner, le partager\n",
        " * chapitres 5->8 : introduction aux modules `datasets`, `tokenizers`, et appréhension des problèmes classiques NLP\n",
        " * chapitres 9->12 : au delà de la NLP, introduction à la speech recognition et à la computer vision, également introduction aux démonstrateurs huggingface ainsi que de la mise en production\n"
      ],
      "metadata": {
        "id": "X-OInPlwwfzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline\n",
        "\n",
        "Il y a cette fonction `pipeline()` dans le module `transformers` qui permet de créer une chaîne qui effectue toutes les étapes suivantes pour un cas d'usage renseigné : \n",
        " * Téléchargement d'un pretrained model adapté au cas d'usage renseigné\n",
        " * le texte est prétraité pour qu’il ait un format compréhensible par le modèle,\n",
        " * les données prétraitées sont passées au modèle,\n",
        " * les prédictions du modèle sont post-traitées de sorte que vous puissiez les comprendre.\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "```\n",
        "\n",
        "```python\n",
        "classifier(\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\"\n",
        ")  # J'ai attendu un cours d'HuggingFace toute ma vie.\n",
        "\n",
        "# On peut passer plusieurs observations dans le modèle directement\n",
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]  # « J'ai attendu un cours d'HuggingFace toute ma vie. »,  « Je déteste tellement ça ! »\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "ESC8Ybt26lXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voici une liste non-exhaustive des pipelines disponibles, la liste exhaustive est disponible ici : https://huggingface.co/docs/transformers/main_classes/pipelines\n",
        "\n",
        " * `feature-extraction` (pour obtenir la représentation vectorielle d’un texte)\n",
        " * `fill-mask`\n",
        " * `ner` (named entity recognition ou reconnaissance d’entités nommées en français)\n",
        " * `question-answering`\n",
        " * `sentiment-analysis`\n",
        " * `summarization`\n",
        " * `text-generation`\n",
        " * `translation`\n",
        " * `zero-shot-classification`"
      ],
      "metadata": {
        "id": "L6s8pI-m8e7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Zero Shot Learning\n",
        "\n",
        "Il s'agit de prédire la classe de morceaux de textes alors qu'aucun finetunning n'a été effectué\n",
        "\n",
        "```python\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    # C'est un cours sur la bibliothèque Transformers\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")\n",
        "```\n",
        "\n",
        "#### Génération de texte\n",
        "\n",
        "Il s'agit de prédire la classe de morceaux de textes alors qu'aucun finetunning n'a été effectué. On peut renseigner les arguments `num_return_sequences` et `max_length` afin de spécifier le nombre de séquences retournées ainsi que leur longueur\n",
        "\n",
        "\n",
        "```python\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\"\n",
        ")  # Dans ce cours, nous vous enseignerons comment\n",
        "```\n",
        "\n",
        "``` python\n",
        "[{'generated_text': 'In this course, we will teach you how to understand and use ' \n",
        "\t\t\t\t\t# Dans ce cours, nous vous enseignerons comment comprendre et utiliser\n",
        "                    'data flow and data interchange when handling user data. We '\n",
        "\t\t\t\t\t# flux de données et l'échange de données lors de la manipulation des données utilisateur. Nous \n",
        "                    'will be working with one or more of the most commonly used ' \n",
        "\t\t\t\t\t# travailleront avec un ou plusieurs des plus couramment utilisés\n",
        "                    'data flows — data flows of various types, as seen by the ' \n",
        "\t\t\t\t\t# flux de données - flux de données de différents types, tels qu'ils sont vus par\n",
        "                    'HTTP'}] # HTTP\n",
        "```"
      ],
      "metadata": {
        "id": "cAIqeUDT-hsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Un modèle du Hub dans un pipeline\n",
        "\n",
        "On peut choisir son modèle dans le Hub de HuggingFace en renseignant l'argument `model`. URL de HFHub : https://huggingface.co/models\n",
        "\n",
        "```python\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    # Dans ce cours, nous vous enseignerons comment\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")\n",
        "```\n",
        "\n",
        "```python\n",
        "[{'generated_text': 'In this course, we will teach you how to manipulate the world and ' \n",
        "\t\t\t\t\t# Dans ce cours, nous vous enseignerons comment manipuler le monde et\n",
        "                    'move your mental and physical capabilities to your advantage.'}, \n",
        "\t\t\t\t\t# utiliser vos capacités mentales et physiques à votre avantage.\n",
        " {'generated_text': 'In this course, we will teach you how to become an expert and ' \n",
        "\t\t\t\t\t# Dans ce cours, nous vous apprendrons comment devenir un expert et\n",
        "                    'practice realtime, and with a hands on experience on both real ' \n",
        "\t\t\t\t\t# pratique en temps réel, et avec une expérience pratique à la fois sur de vrais\n",
        "                    'time and real'}] \n",
        "\t\t\t\t\t# temps et réel\n",
        "```"
      ],
      "metadata": {
        "id": "1K2JzTdtB3xX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remplacement fill_mask\n",
        "\n",
        "La tâche `fill_mask` consiste à prédire les mots manquants dans une phrase.  L'argument `top_k` permet de retourner le top k des mots les plus probables. Le token correspondant au mot masqué n'est pas toujours le même, on doit vérifier son orthographe sur la page du modèle. Par exemple pour le modèle `bert-base-cased` le mot masqué s'écrit `[MASK]`\n",
        "\n",
        "```python\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)\n",
        "```\n",
        "\n",
        "```python\n",
        "[{'sequence': 'This course will teach you all about mathematical models.', \n",
        "# Ce cours vous apprendra tout sur les modèles mathématiques.\n",
        "  'score': 0.19619831442832947,\n",
        "  'token': 30412,\n",
        "  'token_str': ' mathematical'},\n",
        " {'sequence': 'This course will teach you all about computational models.', \n",
        " # Ce cours vous apprendra tout sur les modèles mathématiques.\n",
        "  'score': 0.04052725434303284,\n",
        "  'token': 38163,\n",
        "  'token_str': ' computational'}]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "sYGlg_CIXQ-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NER\n",
        "Tâche qui consiste à prédire le tag de chaque mot. L'argument `grouped_entities = True` permet de rassembler en une seule entité deux mots qui se suivent et qui appartiennent à un même tag\n",
        "\n",
        "```python\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\n",
        "    \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
        ")  # Je m'appelle Sylvain et je travaille à Hugging Face à Brooklyn.\n",
        "```\n",
        "\n",
        "```python\n",
        "[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, \n",
        " {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, \n",
        " {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "c1AHRDABaK6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question Answering\n",
        "\n",
        "Cette tâche consiste à répondre à une question en extrayant la réponse d'un contexte spécifié\n",
        "\n",
        "```python\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work?\",  # Où est-ce que je travaille ?\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        "    # Je m'appelle Sylvain et je travaille à Hugging Face à Brooklyn.\n",
        ")\n",
        "```\n",
        "\n",
        "```python\n",
        "{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}\n",
        "```"
      ],
      "metadata": {
        "id": "eSlRiagKcclM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "La tâche consiste évidemment à résumer un texte long en un texte plus court tout en gardant le sens global. On peut spécifier les arguments suivants : `min_length` et `max_length` afin de d'avoir un résumé de sortie plus ou moins long\n",
        "\n",
        "```python\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of \n",
        "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
        "    the premier American universities engineering curricula now concentrate on \n",
        "    and encourage largely the study of engineering science. As a result, there \n",
        "    are declining offerings in engineering subjects dealing with infrastructure, \n",
        "    the environment, and related issues, and greater concentration on high \n",
        "    technology subjects, largely supporting increasingly complex scientific \n",
        "    developments. While the latter is important, it should not be at the expense \n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other \n",
        "    industrial countries in Europe and Asia, continue to encourage and advance \n",
        "    the teaching of engineering. Both China and India, respectively, graduate \n",
        "    six and eight times as many traditional engineers as does the United States. \n",
        "    Other industrial countries at minimum maintain their output, while America \n",
        "    suffers an increasingly serious decline in the number of engineering graduates \n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "    L'Amérique a changé de façon spectaculaire au cours des dernières années. Non seulement le nombre de \n",
        "    diplômés dans les disciplines traditionnelles de l'ingénierie telles que le génie mécanique, civil, \n",
        "    l'électricité, la chimie et l'aéronautique a diminué, mais dans la plupart \n",
        "    des grandes universités américaines, les programmes d'études d'ingénierie se concentrent désormais sur \n",
        "    et encouragent largement l'étude des sciences de l'ingénieur. Par conséquent, il y a \n",
        "    de moins en moins d'offres dans les sujets d'ingénierie traitant de l'infrastructure, \n",
        "    l'environnement et les questions connexes, et une plus grande concentration sur les sujets de haute \n",
        "    technologie, qui soutiennent en grande partie des développements scientifiques de plus en plus \n",
        "    complexes. Si cette dernière est importante, elle ne doit pas se faire au détriment\n",
        "    de l'ingénierie plus traditionnelle.\n",
        "\n",
        "    Les économies en développement rapide telles que la Chine et l'Inde, ainsi que d'autres \n",
        "    pays industrialisés d'Europe et d'Asie, continuent d'encourager et de promouvoir\n",
        "    l'enseignement de l'ingénierie. La Chine et l'Inde, respectivement, diplôment \n",
        "    six et huit fois plus d'ingénieurs traditionnels que les États-Unis. \n",
        "    Les autres pays industriels maintiennent au minimum leur production, tandis que l'Amérique \n",
        "    souffre d'une baisse de plus en plus importante du nombre de diplômés en ingénierie\n",
        "    et un manque d'ingénieurs bien formés.\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "```python\n",
        "[{'summary_text': ' America has changed dramatically during recent years . The ' \n",
        "\t\t\t\t  # L'Amérique a changé de façon spectaculaire au cours des dernières années. Le\n",
        "                  'number of engineering graduates in the U.S. has declined in ' \n",
        "\t\t\t\t  # nombre de diplômés en ingénierie aux États-Unis a diminué dans\n",
        "                  'traditional engineering disciplines such as mechanical, civil ' \n",
        "\t\t\t\t  # dans les disciplines traditionnelles de l'ingénierie, telles que le génie mécanique, civil\n",
        "                  ', electrical, chemical, and aeronautical engineering . Rapidly ' \n",
        "\t\t\t\t  # l'électricité, la chimie et l'aéronautique. Les économies\n",
        "                  'developing economies such as China and India, as well as other ' \n",
        "\t\t\t\t  # en développement rapide comme la Chine et l'Inde, ainsi que d'autres\n",
        "                  'industrial countries in Europe and Asia, continue to encourage ' \n",
        "\t\t\t\t  # pays industriels d'Europe et d'Asie, continuent d'encourager\n",
        "                  'and advance engineering.'}] \n",
        "\t\t\t\t  # et à faire progresser l'ingénierie.\n",
        "```"
      ],
      "metadata": {
        "id": "t54HolUCc13n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traduction\n",
        "\n",
        "Par défaut, on peut choisir un modèle de traduction de la langue A vers la langue b en spécifiant la task `translation_a_to_b`. Le plus simple reste tout de même de choisir un modèle dans le Hub. Pareil pour le résumé, il y a des arguments `min_length` et `max_length` même si je vois pas vraiment dans quel cas ca devrait être intéressant\n",
        "\n",
        "```python\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "translator(\"Ce cours est produit par Hugging Face.\")\n",
        "```\n",
        "\n",
        "```python\n",
        "[{'translation_text': 'This course is produced by Hugging Face.'}]\n",
        "```"
      ],
      "metadata": {
        "id": "Nh56wh5CeBNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## En bref\n",
        "\n",
        " * Le `hub` contient les modèles pretrained. On peut également *pousser*\n",
        " son propre modèle sur le `hub` et ainsi le rendre disponible à tout le monde"
      ],
      "metadata": {
        "id": "EaqAByDr5D9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6mbprXgU6ko6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}